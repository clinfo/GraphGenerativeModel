import logging
from lib.calculators import AbstractCalculator
from rdkit import Chem
import numpy as np
import pickle
from lib.helpers import Sketcher

class Evaluation(object):
    """
    Keep track of the molecule generated during the training as well as some other metrics.
    """
    def __init__(self, experiment_name: str, reward_calculator: AbstractCalculator) -> None:
        self.stats = []
        self.outputs = []
        self.experiment_name = experiment_name
        self.calculator = reward_calculator

    def add_output(self, output):
        """
        Retrieve multiple information of the molecules generated by the MCTS algorithm
        and store them in the stats variable.
        :param output: output of the mcts alogrithm
        """
        # TODO Needs to reduce the amount of information store once the metric is clear
        score =[]
        bond_number = []
        mol = []
        smiles = []
        self.outputs.append(output)
        if output is None:
            stat = {
                "bond_number": bond_number,
                "mol": mol,
                "smiles": smiles,
                "score": score
            }
            self.stats.append(stat)
        else:
            for o in output:
                # Case of old model
                if len(o["smiles"].split('.')) > 1:
                    mols = [Chem.MolFromSmiles(s) for s in o["smiles"].split('.')]
                    mol_bonds = [len(m.GetBonds()) for m in mols]
                    id_biggest_mol = np.argmax(mol_bonds)
                    bond_number.append(mol_bonds[id_biggest_mol])
                    mol.append(mols[id_biggest_mol])
                    smiles.append(o["smiles"].split('.')[id_biggest_mol])
                    score.append(self.calculator.calculate(mols[id_biggest_mol]))
                else:
                    bond_number.append(len(Chem.MolFromSmiles(o["smiles"]).GetBonds()))
                    mol.append(Chem.MolFromSmiles(o["smiles"]))
                    smiles.append(o["smiles"])
                    score.append(o["score"])

            stat = {
                "bond_number": bond_number,
                "mol": mol,
                "smiles": smiles,
                "score": score,
                "max_reward": np.max(score),
                "mean_reward": np.mean(score),
                "min_reward": np.min(score),
                "max_bond": np.max(bond_number),
                "mean_bond": np.mean(bond_number),
                "min_bond": np.min(bond_number)
            }
            self.stats.append(stat)

    def save_stat(self, config):
        """
        Save the stat of every result until now in a file
        :param config: config of the experiment
        """
        output = {
            'name': self.experiment_name,
            'config': config,
            'stat': self.stats,
            'output': self.outputs
        }
        with open(f'{self.experiment_name}.pkl', 'wb') as handle:
            pickle.dump(output, handle, protocol=pickle.HIGHEST_PROTOCOL)

        logging.info(f"Saved eval result to {self.experiment_name}.pkl")

def compare_evaluation(filename_a, filename_b):
    """
    Take two file generated with evaluation and compare them.
    Generate the molecule of each file.
    :param filename_a: path to a file created with the `save_stat` fonction of the Evaluation class
    :param filename_b: path to a file created with the `save_stat` fonction of the Evaluation class
    TODO Real metric comparison
    """
    def load(filename):
        with open(filename, 'rb') as handle:
            data = pickle.load(handle)
        return data
    output_a = load(filename_a)
    output_b = load(filename_b)
    assert len(output_a['stat']) == len(output_b['stat']), "The two evaluation don't have the same size"
    generate_images(output_a)
    generate_images(output_b)

def generate_images(output):
    """
    Generate smiles output with score and number of bonds.
    :param output: Data store with the `save_stat` fonction of the Evaluation class
    """
    sketcher = Sketcher(output["name"])
    sketcher.draw_from_eval(output)

if __name__ == "__main__":
    compare_evaluation("test_no_hash.pkl", "test_old.pkl")